{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from ops import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "envs = ['CartPole-v1','Acrobot-v1','MountainCar-v0','Pendulum-v0','BipedalWalker-v2','LunarLander-v2']\n",
    "env = gym.make(envs[-2]).unwrapped\n",
    "discrete_actions = False\n",
    "\n",
    "if discrete_actions:\n",
    "    creature_out_size = env.action_space.n\n",
    "else:\n",
    "    creature_out_size = env.action_space.shape[0]\n",
    "    \n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_num = (len(get_params(Creature(env.observation_space.shape[0],creature_out_size)))*2)\n",
    "output_num = len(get_params(Creature(env.observation_space.shape[0],creature_out_size)))\n",
    "\n",
    "mem_length = 10\n",
    "num_mems = 5\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer4 = nn.Linear(16*977, 128)\n",
    "        self.layer5 = nn.Linear(128, mem_length)\n",
    "        self.layer6 = nn.Sequential(       \n",
    "            nn.Linear(mem_length, 1))#,\n",
    "            #nn.Sigmoid())\n",
    "    def forward(self, out,r):\n",
    "        #out = torch.cat([out,r],-1)\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        #out = out * r\n",
    "        out = self.layer6(out)\n",
    "        return out\n",
    "\n",
    "all_a = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w,e,a = WriteHead()(torch.zeros([1,len(get_params(Creature()))]))\n",
    "mem = torch.zeros([num_mems,mem_length])#.transpose(0,1)\n",
    "wee = w.squeeze(0).unsqueeze(-1)*torch.ones([1,mem_length])\n",
    "print(wee.shape,mem.shape)\n",
    "print(F.cosine_similarity(wee,mem))\n",
    "\n",
    "print(write(torch.zeros([3,num_mems,mem_length]),w,e,a).shape)\n",
    "#print(read.shape)\n",
    "#print(torch.matmul(torch.zeros([mem_length,num_mems]),read.squeeze(0)).shape)\n",
    "#print(read(torch.zeros([num_mems,mem_length]),r).shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = np.array([random.randint(0,1000)/10000])\n",
    "a = torch.from_numpy(a).to(device).type(\"torch.cuda.FloatTensor\")\n",
    "gen = Generator().to(device)\n",
    "gen_out = gen(torch.zeros([(len(get_params(Creature())))]).to(device),\n",
    "   torch.zeros([(len(get_params(Creature())))]).to(device),\n",
    "   a)\n",
    "\n",
    "dis = Discriminator().to(device)\n",
    "dis(torch.zeros([10,len(get_params(Creature()))]).to(device),\n",
    "   torch.zeros([10,mem_length]).to(device)).shape    \n",
    "\n",
    "\n",
    "w,e,a = WriteHead().to(device)(gen_out)\n",
    "#w = torch.zeros([2,10]).to(device)\n",
    "memory = torch.zeros([num_mems,mem_length]).to(device)\n",
    "temp_mem = memory.repeat(5,1,1)\n",
    "print(write(memory,w,e,a).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(population,out_size,use_gen,p_fitness,mutation_rate,mutation_scale):\n",
    "    #Chose creatures based on fitness\n",
    "    pick_probabilities = get_pick_probabilities(p_fitness)\n",
    "    choice = np.random.choice(pick_probabilities.size,out_size+1, p = pick_probabilities)\n",
    "    \n",
    "    #mate and mutate creatures\n",
    "    new_population = []\n",
    "    for p in range(out_size):\n",
    "        first_choice = population[choice[p]]\n",
    "        #no incest\n",
    "        second_choice = choice[np.where(choice!=choice[p])]\n",
    "        if second_choice.size >len(population)/2:#!=0:\n",
    "            second_choice = second_choice[random.randint(0,second_choice.size-1)]\n",
    "            second_choice = population[second_choice]\n",
    "        else:\n",
    "            second_choice = population[choice[p+1]]\n",
    "        \n",
    "        par_fit = np.max([p_fitness[choice[p]],p_fitness[choice[p+1]]])\n",
    "        \n",
    "        child = mate(env,creature_out_size,all_a,device,first_choice,second_choice,\n",
    "                     mutation_rate[choice[p]],mutation_rate[choice[p+1]],use_gen,mutation_scale).to(device)\n",
    "        \n",
    "        new_population.append(child)\n",
    "        \n",
    "    \n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_gan(population,p_fitness,batch_size = 20,n_epochs = 100):\n",
    "    p_fitness = torch.from_numpy(p_fitness).type(\"torch.FloatTensor\").to(device)\n",
    "    \n",
    "    gen_loss_all = []\n",
    "    dis_loss_all = []\n",
    "    rec_loss_all = []\n",
    "    for e in range(n_epochs):\n",
    "        #shuffle arrays in unison\n",
    "        #ind = np.arange(len(population))\n",
    "        #np.random.shuffle(ind)\n",
    "        #population = np.array(population)[ind]\n",
    "        #p_fitness = p_fitness[ind]\n",
    "        for i in range(len(population)//batch_size):\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            dis_optimizer.zero_grad()\n",
    "            read_optimizer.zero_grad()\n",
    "            \n",
    "            real_batch = []\n",
    "            #turn population into vectors\n",
    "            for b in range(batch_size):\n",
    "                real_batch.append(get_params(population[(i*batch_size)+b]).unsqueeze(0))\n",
    "            real_batch = torch.cat(real_batch, dim=0).to(device)\n",
    "            \n",
    "            real_read = read_head(real_batch)\n",
    "            real_read = read(memory.unsqueeze(0),real_read,device).squeeze(0)\n",
    "            \n",
    "            #train discriminator on population\n",
    "            dis_out_r = dis(real_batch,real_read.squeeze(1)).squeeze(-1)\n",
    "            rank = p_fitness[i*batch_size:(i*batch_size)+batch_size]\n",
    "            dis_error_real = (nn.MSELoss()(dis_out_r,rank)) * 5\n",
    "            dis_error_real.backward()\n",
    "\n",
    "            #generate children from population\n",
    "            child = gen_children(population,device,gen,batch_size,a = all_a)\n",
    "            fake_read = read_head(child)\n",
    "            fake_read = read(memory.unsqueeze(0),fake_read,device).squeeze(0)\n",
    "            dis_out_f = dis(child,fake_read.squeeze(1)).squeeze(-1)\n",
    "            \n",
    "            #train discriminator on generator output\n",
    "            #if torch.max(dis_out_f)>torch.min(p_fitness):\n",
    "            dis_error_fake = torch.mean(dis_out_f)                 \n",
    "            dis_error_fake.backward(retain_graph=True)\n",
    "            dis_optimizer.step() \n",
    "            read_optimizer.step() \n",
    "            \n",
    "            #train generator\n",
    "            gen_error = -torch.mean(dis_out_f)\n",
    "            total_gen_error = gen_error \n",
    "            total_gen_error.backward()\n",
    "            gen_optimizer.step()\n",
    "            \n",
    "            \n",
    "        #keep losses to draw graph    \n",
    "        gen_loss_all.append(gen_error)\n",
    "        dis_loss_all.append(dis_error_fake)\n",
    "        rec_loss_all.append(dis_error_real)    \n",
    "        #if e %  5 == 0:    \n",
    "        #print(\"Discriminator loss real : {}\".format(dis_error_real))\n",
    "        #print(\"Discriminator loss generated : {}\".format(dis_error_fake))\n",
    "        #print(\"Generator loss : {}\".format(gen_error))\n",
    "        #print(\"Child error : {}\".format(child_error*0.1))\n",
    "        #print(\"\")\n",
    "    return gen_loss_all, dis_loss_all, rec_loss_all\n",
    "\n",
    "def train_write(population,p_fitness,batch_size,n_epochs = 25):\n",
    "    temp_mem = memory.repeat(batch_size,1,1)\n",
    "    pf = torch.from_numpy(p_fitness).type(\"torch.FloatTensor\").to(device)\n",
    "    \n",
    "    total_write_loss = []\n",
    "    for e in range(n_epochs):\n",
    "        write_optimizer.zero_grad()\n",
    "\n",
    "        #turn population into vectors\n",
    "        real_batch = []\n",
    "        for b in range(batch_size):\n",
    "            real_batch.append(get_params(population[b]).unsqueeze(0))\n",
    "        real_batch = torch.cat(real_batch, dim=0).to(device)\n",
    "        \n",
    "        w,e,a = write_head(real_batch,memory.contiguous().view(memory.numel()))\n",
    "        \n",
    "        mem = write(temp_mem,w,e,a,device)\n",
    "        dis_out = []\n",
    "        for idx,m in enumerate(mem):\n",
    "            real_read = read_head(real_batch[idx]).unsqueeze(0)\n",
    "            real_read = read(m.unsqueeze(0),real_read,device).squeeze(0)\n",
    "            d = dis(real_batch[idx].unsqueeze(0),real_read).squeeze(-1)\n",
    "            dis_out.append(d)\n",
    "        dis_out = torch.stack(dis_out).squeeze(1)\n",
    "       \n",
    "        write_loss = nn.MSELoss()(dis_out,pf)\n",
    "        #write_loss = torch.mean(dis_out)\n",
    "        write_loss.backward()\n",
    "        write_optimizer.step()\n",
    "    \n",
    "        total_write_loss.append(write_loss)\n",
    "    \n",
    "    return total_write_loss\n",
    "\n",
    "def write_to_memory(memory,batch_size):\n",
    "    #write to memory\n",
    "    real_batch = []\n",
    "    for b in range(batch_size):\n",
    "        real_batch.append(get_params(population[b]).unsqueeze(0))\n",
    "    real_batch = torch.cat(real_batch, dim=0).to(device)\n",
    "    w,e,a = write_head(real_batch,memory.contiguous().view(memory.numel()))\n",
    "    yeet = memory.unsqueeze(0)\n",
    "    for b in range(batch_size):\n",
    "        yeet = write(yeet,w[b].unsqueeze(0),e[b].unsqueeze(0),a[b].unsqueeze(0),device)#.squeeze(0)\n",
    "    return  yeet.squeeze(0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly inititialise starting population\n",
    "population_size = 2\n",
    "max_population = 20\n",
    "\n",
    "batch_size = population_size\n",
    "out_size = population_size\n",
    "population = []\n",
    "\n",
    "for p in range(population_size):\n",
    "    population.append(Creature(env.observation_space.shape[0],creature_out_size).to(device))\n",
    "\n",
    "gen = Generator(input_num,output_num,device).to(device)\n",
    "dis = Discriminator().to(device)\n",
    "\n",
    "read_head = ReadHead(output_num,num_mems).to(device)\n",
    "write_head = WriteHead(output_num,num_mems,mem_length).to(device)\n",
    "read_optimizer = torch.optim.Adam(read_head.parameters(), lr=0.001,betas=(0.9,0.999))\n",
    "write_optimizer = torch.optim.Adam(write_head.parameters(), lr=0.001,betas=(0.9,0.999))\n",
    "\n",
    "\n",
    "lr = 0.0001\n",
    "epsilon = 0.000001\n",
    "print(\"starting training\")\n",
    "print(len(get_params(Creature(env.observation_space.shape[0],creature_out_size))))\n",
    "n_generations = 300000\n",
    "\n",
    "memory = torch.ones([num_mems,mem_length],requires_grad=False).to(device)\n",
    "\n",
    "for i in range(n_generations):\n",
    "    #reset learning rate decay after every generation\n",
    "    gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr,betas=(0.9,0.999))\n",
    "    dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr,betas=(0.9,0.999))\n",
    "    \n",
    "    #calculate population fitness\n",
    "    p_fitness_ = measure_population_fitness(population,env,device,discrete_actions,min_reward=-100,\n",
    "                                                             max_steps = 1000)\n",
    "    \n",
    "    \n",
    "    print(\"population fitness : {}\".format(p_fitness_))\n",
    "    print(\"mean fit : {}\".format(np.mean(p_fitness_)))\n",
    "    \n",
    "    #normalise population fitness\n",
    "    centered = (p_fitness_-np.min(p_fitness_))**2\n",
    "    p_fitness = ((centered - np.mean(centered))/np.sqrt(np.var(centered)+epsilon))\n",
    "    \n",
    "    write_loss = train_write(population,p_fitness,batch_size = batch_size,n_epochs = 50)\n",
    "    #write_loss = 0\n",
    "    memory = write_to_memory(memory,batch_size)\n",
    "    \n",
    "    #Train GAN\n",
    "    gen_loss, dis_loss,rec_loss = train_gan(population,p_fitness,\n",
    "              batch_size =batch_size,n_epochs = 50)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    #Every ten generations show progress\n",
    "    if i %10 == 0 and i != 0:\n",
    "        fitness = measure_fitness(population[np.argmax(p_fitness)],env,device,discrete_actions,min_reward=-100,\n",
    "                                  render = True,max_steps = 500)\n",
    "    \n",
    "    #Scale of normal distribution used for mutation\n",
    "    mutation_scale = 0.4\n",
    "    \n",
    "    #Calculate rate at which weights are mutated based on relative fitness\n",
    "    centered = (-p_fitness_-np.min(-p_fitness_))\n",
    "    mutation_rate = (centered/np.median(centered))*0.2\n",
    "    mutation_rate = np.clip(mutation_rate,0,1)\n",
    "    print(\"Mutation rate : {}\".format(mutation_rate))\n",
    "    \n",
    "    #progressively grow population at start\n",
    "    if out_size < max_population:\n",
    "        out_size+=2\n",
    "        batch_size = out_size\n",
    "    \n",
    "    #mate and mutate population\n",
    "    population = evolve(population,out_size,gen,p_fitness,\n",
    "                                        mutation_rate,mutation_scale)\n",
    "\n",
    "    \n",
    "    plt.plot(gen_loss,label='gen')\n",
    "    plt.plot(dis_loss,label='dis_fake')\n",
    "    plt.plot(rec_loss,label='dis_real')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.plot(write_loss,label='write')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(memory)\n",
    "    print(\"Generation {}  fitness : {}\".format(i+1,np.max(p_fitness)))\n",
    "    print(\"#################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",input_sizeenv = gym.make(envs[-2]).unwrapped\n",
    "\n",
    "p_fitness = measure_population_fitness(population,env,device,discrete_actions,min_reward=-100,\n",
    "                                                             max_steps = 200)\n",
    "\n",
    "fitness = measure_fitness(population[np.argmax(p_fitness)],env,device,discrete_actions,min_reward=-100,\n",
    "                                  render = True,max_steps = 5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(5).unsqueeze(0)\n",
    "print(X)\n",
    "X = X.repeat(10,1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
