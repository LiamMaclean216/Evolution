{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "envs = ['CartPole-v1','Acrobot-v1','MountainCar-v0','Pendulum-v0','BipedalWalker-v2']\n",
    "env = gym.make(envs[0]).unwrapped\n",
    "\n",
    "discrete_actions = True\n",
    "#TODO\n",
    "#parralel fitness measuring\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Creature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Creature, self).__init__()\n",
    "    \n",
    "        self.layer1 = nn.Linear(env.observation_space.shape[0], 6)\n",
    "        self.layer2 = nn.Linear(6, 6)\n",
    "        \n",
    "        if discrete_actions:\n",
    "            self.layer3 = nn.Linear(6, env.action_space.n)\n",
    "        else:\n",
    "            self.layer3 = nn.Linear(6, env.action_space.shape[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,output_num):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer4 =  nn.Linear(16*14, output_num)\n",
    "    def forward(self, out):\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer4 = nn.Linear(16*59, 128)\n",
    "        self.layer5 = nn.Sequential(       \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, out):\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out\n",
    "#gen = Generator(86).to(device)\n",
    "\n",
    "#gen(torch.zeros([10,86*2]).to(device)).shape\n",
    "\n",
    "#dis = Discriminator().to(device)\n",
    "#dis(torch.zeros([10,86]).to(device)).shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mate(m,d,gen,apply_mutation = True,dominance = 0.5,mutation_rate=0.2):\n",
    "    dom = torch.from_numpy(np.array(dominance)).to(device).unsqueeze(-1).type(\"torch.cuda.FloatTensor\")\n",
    "    child = Creature()\n",
    "    mom = (m)\n",
    "    dad = (d)\n",
    "    #if apply_mutation:\n",
    "    #    mom = mutate(mom,mutation_rate=0.1)\n",
    "    #    dad = mutate(dad,mutation_rate=0.1)\n",
    "    mom = get_params(mom)\n",
    "    dad = get_params(dad)\n",
    "    generated = gen(torch.cat([dad,mom,dom]).unsqueeze(0)).squeeze(0)\n",
    "    child = set_params(child,generated)\n",
    "    #if apply_mutation:\n",
    "    #    child = mutate(child,mutation_rate=0.1)\n",
    "    return child\n",
    "\n",
    "def mutate(creature,mutation_rate=0.2):\n",
    "    new = Creature().to(device)\n",
    "    new.load_state_dict(creature.state_dict()) \n",
    "    for p in new.parameters():\n",
    "\n",
    "        mutation = np.random.normal(scale = 0.07,size = p.data.shape)\n",
    "        mutation *= np.random.choice([1, 0], p.data.shape,p=[mutation_rate,1-mutation_rate])\n",
    "        mutation = torch.from_numpy(mutation).type('torch.FloatTensor').to(device)\n",
    "        p.data += mutation\n",
    "    return new\n",
    "\n",
    "def evolve(population,gen,pf_fitness,mutate):\n",
    "    p_fitness_positive = p_fitness - np.min(p_fitness) + 1\n",
    "    pick_probabilities = get_pick_probabilities(pf_fitness)\n",
    "    \n",
    "    \n",
    "    choice = np.random.choice(pick_probabilities.size,population_size, p = pick_probabilities)\n",
    "    new_population = []\n",
    "    \n",
    "    for p in range(len(population)-1):\n",
    "        first_choice = population[choice[p]]\n",
    "        second_choice = population[choice[p+1]]\n",
    "        #more succesful(healthier?) creature has greater genetic dominance\n",
    "        f1 = p_fitness_positive[p]\n",
    "        f2 = p_fitness_positive[p+1]\n",
    "        if  f1>=f2 :\n",
    "            dominance = (f2/f1) * 0.5\n",
    "            np.clip(dominance,0.3,0.7)\n",
    "            child = mate(second_choice,first_choice,gen, mutate,dominance).to(device)\n",
    "        else:\n",
    "            dominance = (f1/f2) * 0.5\n",
    "            np.clip(dominance,0.3,0.7)\n",
    "            child = mate(first_choice,second_choice,gen, mutate,dominance).to(device)\n",
    "            \n",
    "        new_population.append(child)\n",
    "        \n",
    "    child = mate(population[0],population[len(population)-1],gen, mutate).to(device) \n",
    "    new_population.append(child)\n",
    "    \n",
    "    return new_population\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_gan(population,p_fitness,old_fitness,batch_size = 20,n_epochs = 1000):\n",
    "    cat = np.concatenate([p_fitness,old_fitness])\n",
    "    #min_fit = np.sort(cat)[int(cat.size*0.75)]\n",
    "    min_fit = np.mean(np.sort(cat)[int(cat.size)-25:])\n",
    "    ranking = (p_fitness>=min_fit)*1\n",
    "    print(min_fit)\n",
    "    #ranking = p_fitness - np.min(p_fitness)\n",
    "    #max_fit = np.max(ranking)\n",
    "        \n",
    "    #ranking = ranking / max_fit\n",
    "    #ranking = (ranking>0.5)*ranking\n",
    "    print(ranking)\n",
    "    ranking = torch.from_numpy(ranking).to(device).type(\"torch.cuda.FloatTensor\")\n",
    "    \n",
    "    #print(ranking)\n",
    "   # print(\" \")\n",
    "    for e in range(n_epochs):\n",
    "        \n",
    "        \n",
    "        for i in range(len(population)//batch_size):\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            dis_optimizer.zero_grad()\n",
    "            \n",
    "            real_batch = []\n",
    "            for b in range(batch_size):\n",
    "                real_batch.append(get_params(population[(i*batch_size)+b]).unsqueeze(0))\n",
    "            real_batch = torch.cat(real_batch, dim=0).to(device)\n",
    "\n",
    "            if e % 4 == 0:\n",
    "                #train discriminator on population\n",
    "                dis_out = dis(real_batch).squeeze(-1)\n",
    "                #stack = [ranking[i*batch_size:(i*batch_size)+batch_size],torch.ones(batch_size).to(device)]\n",
    "                #stack = torch.stack(stack)\n",
    "                dis_error_real = nn.BCELoss()(dis_out, ranking[i*batch_size:(i*batch_size)+batch_size])#torch.ones(batch_size).to(device))\n",
    "                #dis_error_real = nn.BCELoss()(dis_out,stack)\n",
    "                \n",
    "                dis_error_real.backward()\n",
    "                #print(\"Discriminator loss real : {}\".format(dis_error_real))\n",
    "        \n",
    "            #train discriminator on generator output\n",
    "            mom = []\n",
    "            dad = []\n",
    "            child = []\n",
    "            dominance = torch.from_numpy((np.random.rand(batch_size)*0.5) + 0.25).to(device).unsqueeze(-1)\n",
    "            dominance = dominance.type(\"torch.cuda.FloatTensor\")\n",
    "            for b in range(batch_size):\n",
    "                m = get_params(random.choice(population))\n",
    "                d = get_params(random.choice(population))\n",
    "                c_data = torch.cat([m,d,dominance[b]]).unsqueeze(0)\n",
    "                #c_data = torch.cat([c_data,dominance[b]]).unsqueeze(0)\n",
    "                c = gen(c_data).squeeze(0)\n",
    "\n",
    "                mom.append(m)\n",
    "                dad.append(d)\n",
    "                child.append(c)\n",
    "                \n",
    "            mom = torch.stack(mom).to(device)\n",
    "            dad = torch.stack(dad).to(device)\n",
    "            child = torch.stack(child).to(device)\n",
    "            dis_out = dis(child).squeeze(-1)\n",
    "            \n",
    "            if e % 2 == 0:\n",
    "                dis_error_fake = nn.BCELoss()(dis_out,torch.zeros(dis_out.shape).to(device)) \n",
    "                dis_error_fake.backward(retain_graph=True)\n",
    "                #print(\"Discriminator loss generated : {}\".format(dis_error_fake))\n",
    "                \n",
    "            \n",
    "            #train generator\n",
    "            mom_loss = torch.pow(torch.sub(child,mom),2) * (dominance)\n",
    "            dad_loss = torch.pow(torch.sub(child,dad),2) * (1-dominance)\n",
    "            \n",
    "            mom_loss = torch.mean(mom_loss)\n",
    "            dad_loss = torch.mean(dad_loss)\n",
    "            if mom_loss > dad_loss:\n",
    "                child_error = torch.div(mom_loss,dad_loss)-1\n",
    "            else:\n",
    "                child_error = torch.div(dad_loss,mom_loss)-1\n",
    "            \n",
    "            \n",
    "            child_error += (mom_loss + dad_loss)\n",
    "            \n",
    "            gen_error = nn.BCELoss()(dis_out,torch.ones(dis_out.shape).to(device)) + (child_error*0.1)  \n",
    "            gen_error.backward()\n",
    "            gen_optimizer.step()\n",
    "            \n",
    "            dis_optimizer.step()\n",
    "            \n",
    "            \n",
    "        \n",
    "            #print(\"Generator loss : {}\".format(gen_error))\n",
    "            #print(\"Child error : {}\".format(child_error))\n",
    "            #print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "[26. 10.  9.  9.  8. 10.  8.  9.  8.  9. 10.  9. 13.  9.  9. 10. 10.  8.\n",
      " 10.  8. 10. 10. 13.  9. 10.  9. 10. 24.  9. 10. 13.  9. 10. 10.  9.  9.\n",
      " 10. 10.  9. 11. 54.  9.  9. 10. 10.  9.  9. 10.  9.  9.]\n",
      "16.72\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "train\n",
      "Generation 1  fitness : 54.0\n",
      "#################################\n",
      "[25. 28. 12.  9. 16.  9. 17. 10.  9. 10. 10.  8. 10. 11. 11. 10.  9. 10.\n",
      "  8.  8. 31. 10. 17. 25. 10.  9. 10.  8. 25. 10.  9. 12.  8. 10. 10. 19.\n",
      " 12.  9. 11.  9. 10. 36.  9.  8. 30. 10.  9. 44.  9.  9.]\n",
      "21.44\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0]\n",
      "train\n",
      "Generation 2  fitness : 44.0\n",
      "#################################\n",
      "[ 9. 10. 10. 10.  9.  8. 10.  8.  8. 10.  9.  9.  9.  9.  9. 10.  9. 10.\n",
      "  8.  9. 10.  9. 10.  9.  9.  8. 10.  9. 10. 16.  8.  9.  9. 10. 10. 10.\n",
      " 10.  9.  9.  9. 11. 18.  9. 10. 22.  8.  9.  9.  9. 10.]\n",
      "19.16\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "train\n",
      "Generation 3  fitness : 22.0\n",
      "#################################\n",
      "[ 9.  8. 10. 10. 11. 27. 65.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9. 10.\n",
      "  9.  9. 10.  9.  9. 10. 10. 10. 10. 10. 16. 40. 13. 25. 39. 10. 10. 10.\n",
      " 11. 83. 61. 10. 23. 11.  9.  9. 14. 10. 10. 10. 10. 14.]\n",
      "23.2\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train\n",
      "Generation 4  fitness : 83.0\n",
      "#################################\n",
      "[10.  9. 10.  9.  9. 10.  9.  9. 10. 10.  9. 10. 10. 46. 25. 10. 10.  9.\n",
      "  9. 10. 10. 24. 16.  8. 14. 10.  9. 16.  9.  9. 25.  9.  9. 34.  9.  9.\n",
      " 11. 24. 11. 22. 14.  8.  9. 11.  9. 15.  9.  9.  9.  9.]\n",
      "28.24\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train\n",
      "Generation 5  fitness : 46.0\n",
      "#################################\n",
      "[19. 13. 11. 10.  8.  8.  9. 10. 10. 10. 10. 31. 25. 17. 11. 14. 55. 10.\n",
      " 12. 26. 12. 25. 10.  9.  9. 18. 35. 15. 71. 10. 10. 17. 22. 20. 12. 14.\n",
      " 21. 50. 13. 13. 15. 16. 28. 27. 23. 13. 11. 13. 10.  9.]\n",
      "29.2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train\n",
      "Generation 6  fitness : 71.0\n",
      "#################################\n",
      "[37. 10. 13. 26. 78. 18. 10. 10. 21. 22. 20. 12. 10. 33. 28. 22. 97. 12.\n",
      " 82. 25. 11. 18. 13. 28. 16. 15. 19. 30. 16. 16. 15. 11. 10. 72.  9. 27.\n",
      " 12. 15. 11.  8. 23. 15. 19. 55. 12. 69. 25. 14. 10. 14.]\n",
      "43.4\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "train\n",
      "Generation 7  fitness : 97.0\n",
      "#################################\n",
      "[ 78. 109.  90. 117.  19.  88.  98.  69.  67. 144. 162. 117.  89.  86.\n",
      "  82.  80.  82.  86.  85.  95. 104. 142. 108.  88. 210. 101. 136. 129.\n",
      "  22.  89. 120. 109. 143. 126.  89.  87.  90.  32.  80.  85. 159. 115.\n",
      " 169.  91.  74. 174.  87.  88.  89.  74.]\n",
      "126.6\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0]\n",
      "train\n",
      "Generation 8  fitness : 210.0\n",
      "#################################\n",
      "[ 85.  31. 135. 138.  93. 368. 171. 137. 152.  74. 164. 160. 468. 102.\n",
      "  81. 160.  76. 100. 152. 204.  71. 117. 197.  92.  43. 101. 282.  87.\n",
      "  77.  18. 184. 167. 223. 184. 268.  65. 227.  92. 131.  95.  81. 135.\n",
      " 164.  73. 146. 116.  81. 116. 281. 161.]\n",
      "208.44\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#randomly inititialise starting population\n",
    "population_size = 50\n",
    "population = []\n",
    "for p in range(population_size):\n",
    "    population.append(Creature().to(device))\n",
    "    \n",
    "gen = Generator(86).to(device)\n",
    "#gen(torch.zeros([10,86*2])).shape\n",
    "\n",
    "dis = Discriminator().to(device)\n",
    "#dis(torch.zeros([10,86])).shape\n",
    "\n",
    "lr = 0.0001\n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "\n",
    "print(\"starting training\")\n",
    "n_generations = 100\n",
    "batch_size = 50\n",
    "for i in range(n_generations):\n",
    "    #gen = Generator(86).to(device)\n",
    "    #dis = Discriminator().to(device)\n",
    "    gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "    #dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_behavior_samples = 50\n",
    "    p_fitness, behavior_samples = measure_population_fitness(population,env,device,discrete_actions,\n",
    "                                                             max_steps = 500, \n",
    "                                                             n_behavior_samples=n_behavior_samples)\n",
    "    print(p_fitness)\n",
    "    if i == 0:\n",
    "        old_fitness = p_fitness\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        train_gan(population,p_fitness,old_fitness,batch_size = batch_size,n_epochs = 50)\n",
    "        print(\"train\")\n",
    "    old_fitness = p_fitness\n",
    "    \n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        fitness = measure_fitness(population[np.argmax(p_fitness)],env,device,discrete_actions,render = True)\n",
    "    population = evolve(population,gen,p_fitness,True)\n",
    "    print(\"Generation {}  fitness : {}\".format(i+1,np.max(p_fitness)))\n",
    "    print(\"#################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeet  = np.arange(10) + 5\n",
    "print(yeet)\n",
    "yeet = np.delete(yeet,np.where(yeet<7)[0])\n",
    "print(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
