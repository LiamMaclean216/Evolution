{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "envs = ['CartPole-v1','Acrobot-v1','MountainCar-v0','Pendulum-v0','BipedalWalker-v2']\n",
    "env = gym.make(envs[0]).unwrapped\n",
    "\n",
    "discrete_actions = True\n",
    "#TODO\n",
    "#parralel fitness measuring\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Creature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Creature, self).__init__()\n",
    "    \n",
    "        self.layer1 = nn.Linear(env.observation_space.shape[0], 6)\n",
    "        self.layer2 = nn.Linear(6, 6)\n",
    "        \n",
    "        if discrete_actions:\n",
    "            self.layer3 = nn.Linear(6, env.action_space.n)\n",
    "        else:\n",
    "            self.layer3 = nn.Linear(6, env.action_space.shape[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,output_num):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer4 =  nn.Linear(16*14, output_num)\n",
    "    def forward(self, out):\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer4 = nn.Linear(16*59, 128)\n",
    "        self.layer5 = nn.Sequential(       \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, out):\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out\n",
    "#gen = Generator(86).to(device)\n",
    "\n",
    "#gen(torch.zeros([10,86*2]).to(device)).shape\n",
    "\n",
    "#dis = Discriminator().to(device)\n",
    "#dis(torch.zeros([10,86]).to(device)).shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mate(m,d,gen,apply_mutation = True,dominance = 0.5,mutation_rate=0.2):\n",
    "    dom = torch.from_numpy(np.array(dominance)).to(device).unsqueeze(-1).type(\"torch.cuda.FloatTensor\")\n",
    "    child = Creature()\n",
    "    mom = (m)\n",
    "    dad = (d)\n",
    "    #if apply_mutation:\n",
    "    #    mom = mutate(mom,mutation_rate=0.1)\n",
    "    #    dad = mutate(dad,mutation_rate=0.1)\n",
    "    mom = get_params(mom)\n",
    "    dad = get_params(dad)\n",
    "    generated = gen(torch.cat([dad,mom,dom]).unsqueeze(0)).squeeze(0)\n",
    "    child = set_params(child,generated)\n",
    "    #if apply_mutation:\n",
    "    #    child = mutate(child,mutation_rate=0.1)\n",
    "    return child\n",
    "\n",
    "def mutate(creature,mutation_rate=0.2):\n",
    "    new = Creature().to(device)\n",
    "    new.load_state_dict(creature.state_dict()) \n",
    "    for p in new.parameters():\n",
    "\n",
    "        mutation = np.random.normal(scale = 0.07,size = p.data.shape)\n",
    "        mutation *= np.random.choice([1, 0], p.data.shape,p=[mutation_rate,1-mutation_rate])\n",
    "        mutation = torch.from_numpy(mutation).type('torch.FloatTensor').to(device)\n",
    "        p.data += mutation\n",
    "    return new\n",
    "\n",
    "def evolve(population,gen,pf_fitness,mutate):\n",
    "    p_fitness_positive = p_fitness - np.min(p_fitness) + 1\n",
    "    pick_probabilities = get_pick_probabilities(pf_fitness)\n",
    "    \n",
    "    \n",
    "    choice = np.random.choice(pick_probabilities.size,population_size, p = pick_probabilities)\n",
    "    new_population = []\n",
    "    \n",
    "    for p in range(len(population)-1):\n",
    "        first_choice = population[choice[p]]\n",
    "        second_choice = population[choice[p+1]]\n",
    "        #more succesful(healthier?) creature has greater genetic dominance\n",
    "        f1 = p_fitness_positive[p]\n",
    "        f2 = p_fitness_positive[p+1]\n",
    "        if  f1>=f2 :\n",
    "            dominance = (f2/f1) * 0.5\n",
    "            np.clip(dominance,0.3,0.7)\n",
    "            child = mate(second_choice,first_choice,gen, mutate,dominance).to(device)\n",
    "        else:\n",
    "            dominance = (f1/f2) * 0.5\n",
    "            np.clip(dominance,0.3,0.7)\n",
    "            child = mate(first_choice,second_choice,gen, mutate,dominance).to(device)\n",
    "            \n",
    "        new_population.append(child)\n",
    "        \n",
    "    child = mate(population[0],population[len(population)-1],gen, mutate).to(device) \n",
    "    new_population.append(child)\n",
    "    \n",
    "    return new_population\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_gan(population,p_fitness,old_max,batch_size = 20,n_epochs = 1000):\n",
    "    #mean = (old_mean+np.mean(p_fitness))/2\n",
    "    #min_fit = np.mean(p_fitness)\n",
    "    min_fit = np.sort(p_fitness)[int(p_fitness.size*0.75)]\n",
    "    ranking = (p_fitness>=min_fit)*1\n",
    "    #ranking = p_fitness - np.min(p_fitness)\n",
    "    \n",
    "    #max_fit = np.max(ranking)\n",
    "        \n",
    "    #ranking = ranking / max_fit\n",
    "    #ranking = (ranking>0.5)*ranking\n",
    "    print(ranking)\n",
    "    ranking = torch.from_numpy(ranking).to(device).type(\"torch.cuda.FloatTensor\")\n",
    "    \n",
    "    #print(ranking)\n",
    "   # print(\" \")\n",
    "    for e in range(n_epochs):\n",
    "        \n",
    "        \n",
    "        for i in range(len(population)//batch_size):\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            dis_optimizer.zero_grad()\n",
    "            \n",
    "            real_batch = []\n",
    "            for b in range(batch_size):\n",
    "                real_batch.append(get_params(population[(i*batch_size)+b]).unsqueeze(0))\n",
    "            real_batch = torch.cat(real_batch, dim=0).to(device)\n",
    "\n",
    "            if e % 4 == 0:\n",
    "                #train discriminator on population\n",
    "                dis_out = dis(real_batch).squeeze(-1)\n",
    "                #stack = [ranking[i*batch_size:(i*batch_size)+batch_size],torch.ones(batch_size).to(device)]\n",
    "                #stack = torch.stack(stack)\n",
    "                dis_error_real = nn.BCELoss()(dis_out, ranking[i*batch_size:(i*batch_size)+batch_size])#torch.ones(batch_size).to(device))\n",
    "                #dis_error_real = nn.BCELoss()(dis_out,stack)\n",
    "                \n",
    "                dis_error_real.backward()\n",
    "                #print(\"Discriminator loss real : {}\".format(dis_error_real))\n",
    "        \n",
    "            #train discriminator on generator output\n",
    "            mom = []\n",
    "            dad = []\n",
    "            child = []\n",
    "            dominance = torch.from_numpy((np.random.rand(batch_size)*0.5) + 0.25).to(device).unsqueeze(-1)\n",
    "            dominance = dominance.type(\"torch.cuda.FloatTensor\")\n",
    "            for b in range(batch_size):\n",
    "                m = get_params(random.choice(population))\n",
    "                d = get_params(random.choice(population))\n",
    "                c_data = torch.cat([m,d,dominance[b]]).unsqueeze(0)\n",
    "                #c_data = torch.cat([c_data,dominance[b]]).unsqueeze(0)\n",
    "                c = gen(c_data).squeeze(0)\n",
    "\n",
    "                mom.append(m)\n",
    "                dad.append(d)\n",
    "                child.append(c)\n",
    "                \n",
    "            mom = torch.stack(mom).to(device)\n",
    "            dad = torch.stack(dad).to(device)\n",
    "            child = torch.stack(child).to(device)\n",
    "            dis_out = dis(child).squeeze(-1)\n",
    "            \n",
    "            if e % 2 == 0:\n",
    "                dis_error_fake = nn.BCELoss()(dis_out,torch.zeros(dis_out.shape).to(device)) \n",
    "                dis_error_fake.backward(retain_graph=True)\n",
    "                #print(\"Discriminator loss generated : {}\".format(dis_error_fake))\n",
    "                \n",
    "            \n",
    "            #train generator\n",
    "            mom_loss = torch.pow(torch.sub(child,mom),2) * (dominance)\n",
    "            dad_loss = torch.pow(torch.sub(child,dad),2) * (1-dominance)\n",
    "            \n",
    "            mom_loss = torch.mean(mom_loss)\n",
    "            dad_loss = torch.mean(dad_loss)\n",
    "            if mom_loss > dad_loss:\n",
    "                child_error = torch.div(mom_loss,dad_loss)-1\n",
    "            else:\n",
    "                child_error = torch.div(dad_loss,mom_loss)-1\n",
    "            \n",
    "            \n",
    "            child_error += (mom_loss + dad_loss)\n",
    "            \n",
    "            gen_error = nn.BCELoss()(dis_out,torch.ones(dis_out.shape).to(device)) + (child_error*0.1)  \n",
    "            gen_error.backward()\n",
    "            gen_optimizer.step()\n",
    "            \n",
    "            dis_optimizer.step()\n",
    "            \n",
    "            \n",
    "        \n",
    "            #print(\"Generator loss : {}\".format(gen_error))\n",
    "            #print(\"Child error : {}\".format(child_error))\n",
    "            #print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "[  9.   8.  17.  10.  10.   9.  21.  13.  83.   9.  10.   8.   9.  10.\n",
      "   9.   8.  47.   9.   8.  10.  10.   9.  36.   8.  10.   8.  10.  10.\n",
      "  13.   9.  27.  10.   8.   9.  35.   9.  10.  10.  31. 201.  11.  10.\n",
      "  10.  10.   9.   9.  16.  10.  10.  10.]\n",
      "[0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 1 1 1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#randomly inititialise starting population\n",
    "population_size = 50\n",
    "population = []\n",
    "for p in range(population_size):\n",
    "    population.append(Creature().to(device))\n",
    "    \n",
    "gen = Generator(86).to(device)\n",
    "#gen(torch.zeros([10,86*2])).shape\n",
    "\n",
    "dis = Discriminator().to(device)\n",
    "#dis(torch.zeros([10,86])).shape\n",
    "\n",
    "lr = 0.0001\n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "\n",
    "print(\"starting training\")\n",
    "n_generations = 100\n",
    "batch_size = 50\n",
    "for i in range(n_generations):\n",
    "    #gen = Generator(86).to(device)\n",
    "    #dis = Discriminator().to(device)\n",
    "    gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "    dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_behavior_samples = 50\n",
    "    p_fitness, behavior_samples = measure_population_fitness(population,env,device,discrete_actions,\n",
    "                                                             max_steps = 500, \n",
    "                                                             n_behavior_samples=n_behavior_samples)\n",
    "    print(p_fitness)\n",
    "    if i == 0:\n",
    "        old_max = np.max(p_fitness)\n",
    "    #print(p_fitness)\n",
    "    #print((p_fitness>np.mean(p_fitness))*1)\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        train_gan(population,p_fitness,old_max,batch_size = batch_size,n_epochs = 50)\n",
    "        print(\"train\")\n",
    "    old_max = np.max(p_fitness)\n",
    "    \n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        fitness = measure_fitness(population[np.argmax(p_fitness)],env,device,discrete_actions,render = True)\n",
    "    population = evolve(population,gen,p_fitness,True)\n",
    "    print(\"Generation {}  fitness : {}\".format(i+1,np.max(p_fitness)))\n",
    "    print(\"#################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeet  = np.arange(10) + 5\n",
    "print(yeet)\n",
    "yeet = np.delete(yeet,np.where(yeet<7)[0])\n",
    "print(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
