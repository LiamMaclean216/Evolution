{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "envs = ['CartPole-v1','Acrobot-v1','MountainCar-v0','Pendulum-v0','BipedalWalker-v2']\n",
    "env = gym.make(envs[0]).unwrapped\n",
    "\n",
    "discrete_actions = True\n",
    "#TODO\n",
    "#parralel fitness measuring\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Creature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Creature, self).__init__()\n",
    "    \n",
    "        self.layer1 = nn.Linear(env.observation_space.shape[0], 6)\n",
    "        self.layer2 = nn.Linear(6, 6)\n",
    "        \n",
    "        if discrete_actions:\n",
    "            self.layer3 = nn.Linear(6, env.action_space.n)\n",
    "        else:\n",
    "            self.layer3 = nn.Linear(6, env.action_space.shape[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,output_num):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        \n",
    "        self.layer4 =  nn.Linear(16*14, output_num)\n",
    "    def forward(self, out):\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 8, 5, stride=1, padding=0),  \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 16, 5, stride=1,padding=0),  \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool1d(2, stride=1))\n",
    "        \n",
    "        self.layer4 = nn.Linear(16*59, 128)\n",
    "        self.layer5 = nn.Sequential(       \n",
    "            nn.Linear(128, 2),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, out):\n",
    "        out = out.unsqueeze(1)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),out.size(1)*out.size(2))\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out\n",
    "#gen = Generator(86).to(device)\n",
    "\n",
    "#gen(torch.zeros([10,86*2]).to(device)).shape\n",
    "\n",
    "#dis = Discriminator().to(device)\n",
    "#dis(torch.zeros([10,86]).to(device)).shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mate(m,d,gen,apply_mutation = True,dominance = 0.5,mutation_rate=0.2):\n",
    "    dom = torch.from_numpy(np.array(dominance)).to(device).unsqueeze(-1).type(\"torch.cuda.FloatTensor\")\n",
    "    child = Creature()\n",
    "    mom = (m)\n",
    "    dad = (d)\n",
    "    if apply_mutation:\n",
    "        mom = mutate(mom,mutation_rate=mutation_rate)\n",
    "        dad = mutate(dad,mutation_rate=mutation_rate)\n",
    "    mom = get_params(mom)\n",
    "    dad = get_params(dad)\n",
    "    generated = gen(torch.cat([dad,mom,dom]).unsqueeze(0)).squeeze(0)\n",
    "    child = set_params(child,generated)\n",
    "    if apply_mutation:\n",
    "        child = mutate(child,mutation_rate=mutation_rate)\n",
    "    return child\n",
    "\n",
    "def mutate(creature,mutation_rate=0.2):\n",
    "    new = Creature().to(device)\n",
    "    new.load_state_dict(creature.state_dict()) \n",
    "    for p in new.parameters():\n",
    "\n",
    "        mutation = np.random.normal(scale = 0.07,size = p.data.shape)\n",
    "        mutation *= np.random.choice([1, 0], p.data.shape,p=[mutation_rate,1-mutation_rate])\n",
    "        mutation = torch.from_numpy(mutation).type('torch.FloatTensor').to(device)\n",
    "        p.data += mutation\n",
    "    return new\n",
    "\n",
    "def evolve(population,gen,pf_fitness,mutate):\n",
    "    p_fitness_positive = p_fitness - np.min(p_fitness) + 1\n",
    "    pick_probabilities = get_pick_probabilities(pf_fitness)\n",
    "    \n",
    "    \n",
    "    choice = np.random.choice(pick_probabilities.size,population_size, p = pick_probabilities)\n",
    "    new_population = []\n",
    "    \n",
    "    for p in range(len(population)-1):\n",
    "        first_choice = population[choice[p]]\n",
    "        second_choice = population[choice[p+1]]\n",
    "        #more succesful(healthier?) creature has greater genetic dominance\n",
    "        f1 = p_fitness_positive[p]\n",
    "        f2 = p_fitness_positive[p+1]\n",
    "        if  f1>=f2 :\n",
    "            dominance = (f2/f1) * 0.5\n",
    "            np.clip(dominance,0.3,0.7)\n",
    "            child = mate(second_choice,first_choice,gen, mutate,dominance).to(device)\n",
    "        else:\n",
    "            dominance = (f1/f2) * 0.5\n",
    "            np.clip(dominance,0.3,0.7)\n",
    "            child = mate(first_choice,second_choice,gen, mutate,dominance).to(device)\n",
    "            \n",
    "        new_population.append(child)\n",
    "        \n",
    "    child = mate(population[0],population[len(population)-1],gen, mutate).to(device) \n",
    "    new_population.append(child)\n",
    "    \n",
    "    return new_population\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_gan(population,p_fitness,old_fitness,batch_size = 20,n_epochs = 100):\n",
    "    \n",
    "    \n",
    "    cat = np.concatenate([p_fitness,old_fitness])\n",
    "    #min_fit = np.sort(cat)[int(cat.size*0.75)]\n",
    "    min_fit = np.mean(np.sort(cat)[int(cat.size)-int(cat.size/2):])\n",
    "    #min_fit2 = np.mean(np.sort(p_fitness)[int(p_fitness.size)-int(p_fitness.size/2):])\n",
    "    \n",
    "    ranking = (p_fitness>=min_fit)*1 * (p_fitness/np.max(p_fitness))\n",
    "    \n",
    "    print(min_fit)\n",
    "        \n",
    "    print(ranking)\n",
    "    #n_epochs = n_epochs - (ranking.size - np.count_nonzero(ranking))\n",
    "    #print(n_epochs)\n",
    "    ranking = torch.from_numpy(ranking).to(device).type(\"torch.cuda.FloatTensor\")\n",
    "    gen_error = 0\n",
    "    for e in range(n_epochs):\n",
    "        \n",
    "        for i in range(len(population)//batch_size):\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            dis_optimizer.zero_grad()\n",
    "            \n",
    "            real_batch = []\n",
    "            for b in range(batch_size):\n",
    "                real_batch.append(get_params(population[(i*batch_size)+b]).unsqueeze(0))\n",
    "            real_batch = torch.cat(real_batch, dim=0).to(device)\n",
    "\n",
    "            if e % 2 == 0:\n",
    "                #train discriminator on population\n",
    "                dis_out = dis(real_batch).squeeze(-1)\n",
    "                #if e == 0 and i == 0:\n",
    "                \n",
    "                    \n",
    "                stack = [ranking[i*batch_size:(i*batch_size)+batch_size],torch.ones(batch_size).to(device)]\n",
    "                stack = torch.stack(stack)\n",
    "                #print(dis_out)\n",
    "                #print(stack.transpose(0,1))\n",
    "                #dis_error_real = nn.BCELoss()(dis_out, ranking[i*batch_size:(i*batch_size)+batch_size])#torch.ones(batch_size).to(device))\n",
    "                dis_error_real = nn.BCELoss()(dis_out,stack.transpose(0,1))\n",
    "                \n",
    "                dis_error_real.backward()\n",
    "                #print(\"Discriminator loss real : {}\".format(dis_error_real))\n",
    "        \n",
    "            #train discriminator on generator output\n",
    "            mom = []\n",
    "            dad = []\n",
    "            child = []\n",
    "            dominance = torch.from_numpy((np.random.rand(batch_size)*0.5) + 0.25).to(device).unsqueeze(-1)\n",
    "            dominance = dominance.type(\"torch.cuda.FloatTensor\")\n",
    "            for b in range(batch_size):\n",
    "                m = get_params(random.choice(population))\n",
    "                d = get_params(random.choice(population))\n",
    "                c_data = torch.cat([m,d,dominance[b]]).unsqueeze(0)\n",
    "                #c_data = torch.cat([c_data,dominance[b]]).unsqueeze(0)\n",
    "                c = gen(c_data).squeeze(0)\n",
    "\n",
    "                mom.append(m)\n",
    "                dad.append(d)\n",
    "                child.append(c)\n",
    "            \n",
    "            mom = torch.stack(mom).to(device)\n",
    "            dad = torch.stack(dad).to(device)\n",
    "            child = torch.stack(child).to(device)\n",
    "            dis_out = dis(child).squeeze(-1)\n",
    "            \n",
    "            if gen_error < 1:\n",
    "                dis_error_fake = nn.BCELoss()(dis_out,torch.zeros(dis_out.shape).to(device)) \n",
    "                dis_error_fake.backward(retain_graph=True)\n",
    "                #print(\"Discriminator loss generated : {}\".format(dis_error_fake))\n",
    "            dis_optimizer.step()        \n",
    "            \n",
    "            #train generator\n",
    "            if e % 1 == 0:\n",
    "                mom_loss = torch.pow(torch.sub(child,mom),2) * (dominance)\n",
    "                dad_loss = torch.pow(torch.sub(child,dad),2) * (1-dominance)\n",
    "\n",
    "                mom_loss = torch.mean(mom_loss)\n",
    "                dad_loss = torch.mean(dad_loss)\n",
    "                if mom_loss > dad_loss:\n",
    "                    child_error = torch.div(mom_loss,dad_loss)-1\n",
    "                else:\n",
    "                    child_error = torch.div(dad_loss,mom_loss)-1\n",
    "\n",
    "\n",
    "                child_error += (mom_loss + dad_loss)\n",
    "\n",
    "                gen_error = nn.BCELoss()(dis_out,torch.ones(dis_out.shape).to(device)) + (child_error*0.1)  \n",
    "                gen_error.backward()\n",
    "                gen_optimizer.step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            #print(\"Generator loss : {}\".format(gen_error))\n",
    "            #print(\"Child error : {}\".format(child_error*0.1))\n",
    "            #print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "[10.  9.  9. 70. 10.  9. 10. 10.  9. 24. 10.  9.  8.  9. 10. 10.  9. 10.\n",
      "  9. 10. 11. 10. 10. 10. 52. 10. 10. 10. 10. 10. 10. 10. 10.  9.  9. 10.\n",
      "  8.  9. 10.  9.  9.  9. 16.  9. 10.  9.  9.  8. 10.  9.]\n",
      "14.92\n",
      "[0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.34285714 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.74285714 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.22857143 0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Discriminator loss real : 0.6333796977996826\n",
      "Discriminator loss generated : 0.6732639074325562\n",
      "Generator loss : 0.7433074712753296\n",
      "Child error : 0.02295459248125553\n",
      "\n",
      "Discriminator loss generated : 0.5912482738494873\n",
      "Generator loss : 0.8515435457229614\n",
      "Child error : 0.030221182852983475\n",
      "\n",
      "Discriminator loss real : 0.568127453327179\n",
      "Discriminator loss generated : 0.5098517537117004\n",
      "Generator loss : 0.9650903940200806\n",
      "Child error : 0.026402032002806664\n",
      "\n",
      "Discriminator loss generated : 0.45125821232795715\n",
      "Generator loss : 1.0915372371673584\n",
      "Child error : 0.04540020227432251\n",
      "\n",
      "Discriminator loss real : 0.5448919534683228\n",
      "Generator loss : 1.1832695007324219\n",
      "Child error : 0.02150478959083557\n",
      "\n",
      "Generator loss : 1.263993501663208\n",
      "Child error : 0.031473465263843536\n",
      "\n",
      "Discriminator loss real : 0.5145034193992615\n",
      "Generator loss : 1.3302507400512695\n",
      "Child error : 0.02576691471040249\n",
      "\n",
      "Generator loss : 1.365537405014038\n",
      "Child error : 0.021245798096060753\n",
      "\n",
      "Discriminator loss real : 0.4721442759037018\n",
      "Generator loss : 1.38590407371521\n",
      "Child error : 0.028590185567736626\n",
      "\n",
      "Generator loss : 1.4100170135498047\n",
      "Child error : 0.04262701794505119\n",
      "\n",
      "Discriminator loss real : 0.42340853810310364\n",
      "Generator loss : 1.4118521213531494\n",
      "Child error : 0.02866615168750286\n",
      "\n",
      "Generator loss : 1.3998234272003174\n",
      "Child error : 0.032034777104854584\n",
      "\n",
      "Discriminator loss real : 0.37328988313674927\n",
      "Generator loss : 1.3636412620544434\n",
      "Child error : 0.02533685974776745\n",
      "\n",
      "Generator loss : 1.3602138757705688\n",
      "Child error : 0.035173844546079636\n",
      "\n",
      "Discriminator loss real : 0.32556065917015076\n",
      "Generator loss : 1.3429350852966309\n",
      "Child error : 0.030956273898482323\n",
      "\n",
      "Generator loss : 1.3570001125335693\n",
      "Child error : 0.026257922872900963\n",
      "\n",
      "Discriminator loss real : 0.2826520800590515\n",
      "Generator loss : 1.340936541557312\n",
      "Child error : 0.029471999034285545\n",
      "\n",
      "Generator loss : 1.3252248764038086\n",
      "Child error : 0.03132383152842522\n",
      "\n",
      "Discriminator loss real : 0.2457103133201599\n",
      "Generator loss : 1.2946146726608276\n",
      "Child error : 0.03142140805721283\n",
      "\n",
      "Generator loss : 1.3006653785705566\n",
      "Child error : 0.03164655715227127\n",
      "\n",
      "Discriminator loss real : 0.21485428512096405\n",
      "Generator loss : 1.3025389909744263\n",
      "Child error : 0.03637438267469406\n",
      "\n",
      "Generator loss : 1.2832562923431396\n",
      "Child error : 0.032096270471811295\n",
      "\n",
      "Discriminator loss real : 0.1896350234746933\n",
      "Generator loss : 1.2920910120010376\n",
      "Child error : 0.04777369648218155\n",
      "\n",
      "Generator loss : 1.2658767700195312\n",
      "Child error : 0.03267231956124306\n",
      "\n",
      "Discriminator loss real : 0.1692780703306198\n",
      "Generator loss : 1.266493320465088\n",
      "Child error : 0.03640231117606163\n",
      "\n",
      "Generator loss : 1.272823452949524\n",
      "Child error : 0.042314138263463974\n",
      "\n",
      "Discriminator loss real : 0.1529269963502884\n",
      "Generator loss : 1.2457818984985352\n",
      "Child error : 0.028849482536315918\n",
      "\n",
      "Generator loss : 1.255030870437622\n",
      "Child error : 0.03728018328547478\n",
      "\n",
      "Discriminator loss real : 0.13977399468421936\n",
      "Generator loss : 1.257383942604065\n",
      "Child error : 0.0401611253619194\n",
      "\n",
      "Generator loss : 1.2412716150283813\n",
      "Child error : 0.03914053738117218\n",
      "\n",
      "Discriminator loss real : 0.12913593649864197\n",
      "Generator loss : 1.2567013502120972\n",
      "Child error : 0.05918353423476219\n",
      "\n",
      "Generator loss : 1.2332570552825928\n",
      "Child error : 0.03516574203968048\n",
      "\n",
      "Discriminator loss real : 0.12043405324220657\n",
      "Generator loss : 1.2258110046386719\n",
      "Child error : 0.03984422609210014\n",
      "\n",
      "Generator loss : 1.2326905727386475\n",
      "Child error : 0.04207509756088257\n",
      "\n",
      "Discriminator loss real : 0.11321030557155609\n",
      "Generator loss : 1.231594443321228\n",
      "Child error : 0.038399744778871536\n",
      "\n",
      "Generator loss : 1.2292929887771606\n",
      "Child error : 0.04174710065126419\n",
      "\n",
      "Discriminator loss real : 0.10713791847229004\n",
      "Generator loss : 1.2195138931274414\n",
      "Child error : 0.03499561548233032\n",
      "\n",
      "Generator loss : 1.214180827140808\n",
      "Child error : 0.04080400988459587\n",
      "\n",
      "Discriminator loss real : 0.10194376856088638\n",
      "Generator loss : 1.2175357341766357\n",
      "Child error : 0.04084044694900513\n",
      "\n",
      "Generator loss : 1.2107582092285156\n",
      "Child error : 0.04009203612804413\n",
      "\n",
      "Discriminator loss real : 0.09744194895029068\n",
      "Generator loss : 1.2165049314498901\n",
      "Child error : 0.052765846252441406\n",
      "\n",
      "Generator loss : 1.1960363388061523\n",
      "Child error : 0.04151814430952072\n",
      "\n",
      "Discriminator loss real : 0.09346724301576614\n",
      "Generator loss : 1.1802157163619995\n",
      "Child error : 0.03573562577366829\n",
      "\n",
      "Generator loss : 1.2027957439422607\n",
      "Child error : 0.05114530399441719\n",
      "\n",
      "Discriminator loss real : 0.08994772285223007\n",
      "Generator loss : 1.178799033164978\n",
      "Child error : 0.04447413608431816\n",
      "\n",
      "Generator loss : 1.1687735319137573\n",
      "Child error : 0.044033557176589966\n",
      "\n",
      "Discriminator loss real : 0.08676767349243164\n",
      "Generator loss : 1.1637868881225586\n",
      "Child error : 0.042375266551971436\n",
      "\n",
      "Generator loss : 1.1560736894607544\n",
      "Child error : 0.04824083298444748\n",
      "\n",
      "Discriminator loss real : 0.08385797590017319\n",
      "Generator loss : 1.151687502861023\n",
      "Child error : 0.04044148698449135\n",
      "\n",
      "Generator loss : 1.135006308555603\n",
      "Child error : 0.043230216950178146\n",
      "\n",
      "Discriminator loss real : 0.0811699777841568\n",
      "Generator loss : 1.1314668655395508\n",
      "Child error : 0.045200642198324203\n",
      "\n",
      "Generator loss : 1.1326804161071777\n",
      "Child error : 0.05359823629260063\n",
      "\n",
      "Discriminator loss real : 0.0786919966340065\n",
      "Generator loss : 1.1141867637634277\n",
      "Child error : 0.042208701372146606\n",
      "\n",
      "Generator loss : 1.1062557697296143\n",
      "Child error : 0.045561518520116806\n",
      "\n",
      "Discriminator loss real : 0.07636985182762146\n",
      "Generator loss : 1.089207410812378\n",
      "Child error : 0.044058483093976974\n",
      "\n",
      "Generator loss : 1.0868722200393677\n",
      "Child error : 0.045727215707302094\n",
      "\n",
      "Discriminator loss real : 0.0741812065243721\n",
      "Generator loss : 1.0803807973861694\n",
      "Child error : 0.043833520263433456\n",
      "\n",
      "Generator loss : 1.0797579288482666\n",
      "Child error : 0.05287839099764824\n",
      "\n",
      "Discriminator loss real : 0.07210076600313187\n",
      "Generator loss : 1.055283546447754\n",
      "Child error : 0.04435348138213158\n",
      "\n",
      "Generator loss : 1.0586313009262085\n",
      "Child error : 0.05376022681593895\n",
      "\n",
      "Discriminator loss real : 0.07010140269994736\n",
      "Generator loss : 1.0557196140289307\n",
      "Child error : 0.062335677444934845\n",
      "\n",
      "Generator loss : 1.0199443101882935\n",
      "Child error : 0.04476519301533699\n",
      "\n",
      "Discriminator loss real : 0.06816503405570984\n",
      "Generator loss : 1.0284312963485718\n",
      "Child error : 0.058605290949344635\n",
      "\n",
      "Generator loss : 1.016831874847412\n",
      "Child error : 0.050624337047338486\n",
      "\n",
      "Discriminator loss real : 0.06630244106054306\n",
      "Generator loss : 0.9984931349754333\n",
      "Child error : 0.04857202246785164\n",
      "\n",
      "Discriminator loss generated : 2.2150352001190186\n",
      "Generator loss : 0.9865760207176208\n",
      "Child error : 0.048596564680337906\n",
      "\n",
      "Discriminator loss real : 0.06560787558555603\n",
      "Discriminator loss generated : 2.1158647537231445\n",
      "Generator loss : 1.0040353536605835\n",
      "Child error : 0.05011442303657532\n",
      "\n",
      "Generator loss : 1.036865472793579\n",
      "Child error : 0.0540342703461647\n",
      "\n",
      "Discriminator loss real : 0.0679466500878334\n",
      "Generator loss : 1.0528888702392578\n",
      "Child error : 0.04776566103100777\n",
      "\n",
      "Generator loss : 1.0909063816070557\n",
      "Child error : 0.056688036769628525\n",
      "\n",
      "Discriminator loss real : 0.0706009566783905\n",
      "Generator loss : 1.1067183017730713\n",
      "Child error : 0.053332507610321045\n",
      "\n",
      "Generator loss : 1.137033224105835\n",
      "Child error : 0.05895703658461571\n",
      "\n",
      "Discriminator loss real : 0.07315987348556519\n",
      "Generator loss : 1.1461021900177002\n",
      "Child error : 0.058453094214200974\n",
      "\n",
      "Generator loss : 1.1591709852218628\n",
      "Child error : 0.0658462792634964\n",
      "\n",
      "Discriminator loss real : 0.0753178596496582\n",
      "Generator loss : 1.18718683719635\n",
      "Child error : 0.07179460674524307\n",
      "\n",
      "Generator loss : 1.1784003973007202\n",
      "Child error : 0.05272284895181656\n",
      "\n",
      "Discriminator loss real : 0.0769660547375679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator loss : 1.1861158609390259\n",
      "Child error : 0.06096949055790901\n",
      "\n",
      "Generator loss : 1.2026110887527466\n",
      "Child error : 0.0515454076230526\n",
      "\n",
      "Discriminator loss real : 0.07801205664873123\n",
      "Generator loss : 1.2142105102539062\n",
      "Child error : 0.06579436361789703\n",
      "\n",
      "Generator loss : 1.2042609453201294\n",
      "Child error : 0.0580889955163002\n",
      "\n",
      "Discriminator loss real : 0.07844047248363495\n",
      "Generator loss : 1.2116808891296387\n",
      "Child error : 0.0666377991437912\n",
      "\n",
      "Generator loss : 1.205862283706665\n",
      "Child error : 0.06113713979721069\n",
      "\n",
      "Discriminator loss real : 0.07828269153833389\n",
      "Generator loss : 1.208135724067688\n",
      "Child error : 0.06205456331372261\n",
      "\n",
      "Generator loss : 1.2036086320877075\n",
      "Child error : 0.051369499415159225\n",
      "\n",
      "Discriminator loss real : 0.07760680466890335\n",
      "Generator loss : 1.2035918235778809\n",
      "Child error : 0.057685673236846924\n",
      "\n",
      "Generator loss : 1.1999220848083496\n",
      "Child error : 0.06007678434252739\n",
      "\n",
      "Discriminator loss real : 0.07651958614587784\n",
      "Generator loss : 1.1791108846664429\n",
      "Child error : 0.05801903083920479\n",
      "\n",
      "Generator loss : 1.1819528341293335\n",
      "Child error : 0.060898371040821075\n",
      "\n",
      "Discriminator loss real : 0.07510053366422653\n",
      "Generator loss : 1.1739211082458496\n",
      "Child error : 0.05302351713180542\n",
      "\n",
      "Generator loss : 1.168657660484314\n",
      "Child error : 0.056144047528505325\n",
      "\n",
      "Discriminator loss real : 0.07344185560941696\n",
      "Generator loss : 1.1450746059417725\n",
      "Child error : 0.0529901348054409\n",
      "\n",
      "Generator loss : 1.1460278034210205\n",
      "Child error : 0.059884488582611084\n",
      "\n",
      "Discriminator loss real : 0.07163358479738235\n",
      "Generator loss : 1.1351912021636963\n",
      "Child error : 0.05716254189610481\n",
      "\n",
      "Generator loss : 1.1246856451034546\n",
      "Child error : 0.06814243644475937\n",
      "\n",
      "Discriminator loss real : 0.06974629312753677\n",
      "Generator loss : 1.119375228881836\n",
      "Child error : 0.06160806491971016\n",
      "\n",
      "Generator loss : 1.1135653257369995\n",
      "Child error : 0.06519565731287003\n",
      "\n",
      "Discriminator loss real : 0.06781136244535446\n",
      "Generator loss : 1.0838855504989624\n",
      "Child error : 0.05833481624722481\n",
      "\n",
      "Generator loss : 1.0916203260421753\n",
      "Child error : 0.07631149142980576\n",
      "\n",
      "Discriminator loss real : 0.06587815284729004\n",
      "Generator loss : 1.0605504512786865\n",
      "Child error : 0.05703888460993767\n",
      "\n",
      "Generator loss : 1.053995966911316\n",
      "Child error : 0.06462997943162918\n",
      "\n",
      "Discriminator loss real : 0.06397321075201035\n",
      "Generator loss : 1.052624225616455\n",
      "Child error : 0.05913977697491646\n",
      "\n",
      "Generator loss : 1.0362187623977661\n",
      "Child error : 0.0682302936911583\n",
      "\n",
      "Discriminator loss real : 0.062115855515003204\n",
      "Generator loss : 1.017568588256836\n",
      "Child error : 0.06586489081382751\n",
      "\n",
      "Generator loss : 1.0090184211730957\n",
      "Child error : 0.06624597311019897\n",
      "\n",
      "Discriminator loss real : 0.060321200639009476\n",
      "Generator loss : 1.0101491212844849\n",
      "Child error : 0.07880386710166931\n",
      "\n",
      "Generator loss : 0.9786460399627686\n",
      "Child error : 0.06241070106625557\n",
      "\n",
      "Discriminator loss real : 0.05860802158713341\n",
      "Discriminator loss generated : 1.206458330154419\n",
      "Generator loss : 0.970460057258606\n",
      "Child error : 0.06363631784915924\n",
      "\n",
      "Discriminator loss generated : 1.129143238067627\n",
      "Generator loss : 0.994416356086731\n",
      "Child error : 0.06302992254495621\n",
      "\n",
      "Discriminator loss real : 0.061292875558137894\n",
      "Discriminator loss generated : 0.9881393909454346\n",
      "Generator loss : 1.0503249168395996\n",
      "Child error : 0.06554035097360611\n",
      "\n",
      "Generator loss : 1.143345594406128\n",
      "Child error : 0.06319166719913483\n",
      "\n",
      "Discriminator loss real : 0.06785735487937927\n",
      "Generator loss : 1.234865665435791\n",
      "Child error : 0.07858036458492279\n",
      "\n",
      "Generator loss : 1.2916269302368164\n",
      "Child error : 0.06591355800628662\n",
      "\n",
      "Discriminator loss real : 0.07438106834888458\n",
      "Generator loss : 1.357055425643921\n",
      "Child error : 0.06279956549406052\n",
      "\n",
      "Generator loss : 1.4292162656784058\n",
      "Child error : 0.06893550604581833\n",
      "\n",
      "Discriminator loss real : 0.08006260544061661\n",
      "Generator loss : 1.4813026189804077\n",
      "Child error : 0.06257214397192001\n",
      "\n",
      "Generator loss : 1.5440188646316528\n",
      "Child error : 0.07476533204317093\n",
      "\n",
      "Discriminator loss real : 0.08450321108102798\n",
      "Generator loss : 1.572327971458435\n",
      "Child error : 0.06971212476491928\n",
      "\n",
      "Generator loss : 1.607581615447998\n",
      "Child error : 0.06259274482727051\n",
      "\n",
      "Discriminator loss real : 0.08747856318950653\n",
      "Generator loss : 1.6414633989334106\n",
      "Child error : 0.06512404978275299\n",
      "\n",
      "Generator loss : 1.6688050031661987\n",
      "Child error : 0.06644628942012787\n",
      "\n",
      "Discriminator loss real : 0.08900072425603867\n",
      "Generator loss : 1.7160651683807373\n",
      "Child error : 0.08516859263181686\n",
      "\n",
      "Generator loss : 1.707777738571167\n",
      "Child error : 0.06371860951185226\n",
      "\n",
      "Discriminator loss real : 0.08918149024248123\n",
      "Generator loss : 1.7294220924377441\n",
      "Child error : 0.06565345823764801\n",
      "\n",
      "Generator loss : 1.7473584413528442\n",
      "Child error : 0.0731881856918335\n",
      "\n",
      "Discriminator loss real : 0.08822423219680786\n",
      "Generator loss : 1.7419534921646118\n",
      "Child error : 0.06275039166212082\n",
      "\n",
      "Generator loss : 1.7432399988174438\n",
      "Child error : 0.06402482837438583\n",
      "\n",
      "Discriminator loss real : 0.0863727554678917\n",
      "Generator loss : 1.744032621383667\n",
      "Child error : 0.06627871096134186\n",
      "\n",
      "Generator loss : 1.759751319885254\n",
      "Child error : 0.06587094068527222\n",
      "\n",
      "Discriminator loss real : 0.08387088775634766\n",
      "Generator loss : 1.749692678451538\n",
      "Child error : 0.06463927030563354\n",
      "\n",
      "Generator loss : 1.7409625053405762\n",
      "Child error : 0.06356602907180786\n",
      "\n",
      "Discriminator loss real : 0.080954410135746\n",
      "Generator loss : 1.7356317043304443\n",
      "Child error : 0.06433313339948654\n",
      "\n",
      "Generator loss : 1.7342826128005981\n",
      "Child error : 0.07282997667789459\n",
      "\n",
      "Discriminator loss real : 0.07782185822725296\n",
      "Generator loss : 1.7159430980682373\n",
      "Child error : 0.06475023180246353\n",
      "\n",
      "Generator loss : 1.7155436277389526\n",
      "Child error : 0.07713844627141953\n",
      "\n",
      "Discriminator loss real : 0.0746205672621727\n",
      "Generator loss : 1.6955220699310303\n",
      "Child error : 0.06322299689054489\n",
      "\n",
      "Generator loss : 1.677963137626648\n",
      "Child error : 0.06507918983697891\n",
      "\n",
      "Discriminator loss real : 0.07144881039857864\n",
      "Generator loss : 1.6624211072921753\n",
      "Child error : 0.07157967239618301\n",
      "\n",
      "Generator loss : 1.6590211391448975\n",
      "Child error : 0.07408193498849869\n",
      "\n",
      "Discriminator loss real : 0.06838753819465637\n",
      "Generator loss : 1.6458642482757568\n",
      "Child error : 0.07020948082208633\n",
      "\n",
      "Generator loss : 1.639453649520874\n",
      "Child error : 0.0726345032453537\n",
      "\n",
      "Discriminator loss real : 0.06548550724983215\n",
      "Generator loss : 1.6206276416778564\n",
      "Child error : 0.0640970841050148\n",
      "\n",
      "Generator loss : 1.617832899093628\n",
      "Child error : 0.07141286879777908\n",
      "\n",
      "Discriminator loss real : 0.06276479363441467\n",
      "Generator loss : 1.6042699813842773\n",
      "Child error : 0.07048206776380539\n",
      "\n",
      "Generator loss : 1.5886225700378418\n",
      "Child error : 0.06936988234519958\n",
      "\n",
      "Discriminator loss real : 0.060245104134082794\n",
      "Generator loss : 1.5702863931655884\n",
      "Child error : 0.06848859041929245\n",
      "\n",
      "Generator loss : 1.5664823055267334\n",
      "Child error : 0.07630719989538193\n",
      "\n",
      "Discriminator loss real : 0.05793876200914383\n",
      "Generator loss : 1.5498919486999512\n",
      "Child error : 0.07010074704885483\n",
      "\n",
      "Generator loss : 1.524863839149475\n",
      "Child error : 0.06696601212024689\n",
      "\n",
      "Discriminator loss real : 0.05581750348210335\n",
      "Generator loss : 1.508932113647461\n",
      "Child error : 0.06932713091373444\n",
      "\n",
      "Generator loss : 1.5068303346633911\n",
      "Child error : 0.07040619105100632\n",
      "\n",
      "train\n",
      "Generation 1  fitness : 70.0\n",
      "#################################\n",
      "[48. 68. 90. 58. 11. 22. 25. 21. 13. 16. 40. 22. 14.  9. 11. 34. 16.  9.\n",
      " 91. 20. 41. 11. 10. 17. 10. 61. 17. 34. 40. 25. 16. 41. 26. 13. 26. 43.\n",
      " 70. 14. 51. 15. 39. 12. 31. 57. 24. 52. 25. 28. 20. 39.]\n",
      "33.4\n",
      "[0.52747253 0.74725275 0.98901099 0.63736264 0.         0.\n",
      " 0.         0.         0.         0.         0.43956044 0.\n",
      " 0.         0.         0.         0.37362637 0.         0.\n",
      " 1.         0.         0.45054945 0.         0.         0.\n",
      " 0.         0.67032967 0.         0.37362637 0.43956044 0.\n",
      " 0.         0.45054945 0.         0.         0.         0.47252747\n",
      " 0.76923077 0.         0.56043956 0.         0.42857143 0.\n",
      " 0.         0.62637363 0.         0.57142857 0.         0.\n",
      " 0.         0.42857143]\n",
      "Discriminator loss real : 0.555034875869751\n",
      "Discriminator loss generated : 0.5255387425422668\n",
      "Generator loss : 1.5108262300491333\n",
      "Child error : 0.012383874505758286\n",
      "\n",
      "Generator loss : 1.4876855611801147\n",
      "Child error : 0.016738897189497948\n",
      "\n",
      "Discriminator loss real : 0.5710642337799072\n",
      "Generator loss : 1.4570242166519165\n",
      "Child error : 0.014969147741794586\n",
      "\n",
      "Generator loss : 1.3871773481369019\n",
      "Child error : 0.010902795009315014\n",
      "\n",
      "Discriminator loss real : 0.5327953100204468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator loss : 1.3402729034423828\n",
      "Child error : 0.014610156416893005\n",
      "\n",
      "Generator loss : 1.2627934217453003\n",
      "Child error : 0.019916431978344917\n",
      "\n",
      "Discriminator loss real : 0.4675464332103729\n",
      "Generator loss : 1.186500906944275\n",
      "Child error : 0.01672556810081005\n",
      "\n",
      "Generator loss : 1.1054362058639526\n",
      "Child error : 0.012408599257469177\n",
      "\n",
      "Discriminator loss real : 0.40020057559013367\n",
      "Generator loss : 1.0402483940124512\n",
      "Child error : 0.015993423759937286\n",
      "\n",
      "Generator loss : 0.9624080657958984\n",
      "Child error : 0.014867807738482952\n",
      "\n",
      "Discriminator loss real : 0.34678763151168823\n",
      "Discriminator loss generated : 1.21445894241333\n",
      "Generator loss : 0.9226092100143433\n",
      "Child error : 0.01901078037917614\n",
      "\n",
      "Discriminator loss generated : 1.1621901988983154\n",
      "Generator loss : 0.8920885920524597\n",
      "Child error : 0.014873321168124676\n",
      "\n",
      "Discriminator loss real : 0.3643268644809723\n",
      "Discriminator loss generated : 1.0004699230194092\n",
      "Generator loss : 0.9189770221710205\n",
      "Child error : 0.026446564123034477\n",
      "\n",
      "Discriminator loss generated : 0.8086310625076294\n",
      "Generator loss : 0.95815509557724\n",
      "Child error : 0.023217452690005302\n",
      "\n",
      "Discriminator loss real : 0.44629454612731934\n",
      "Discriminator loss generated : 0.6205558180809021\n",
      "Generator loss : 1.04653799533844\n",
      "Child error : 0.012339625507593155\n",
      "\n",
      "Generator loss : 1.199729084968567\n",
      "Child error : 0.039170797914266586\n",
      "\n",
      "Discriminator loss real : 0.5705789923667908\n",
      "Generator loss : 1.2900341749191284\n",
      "Child error : 0.012564162723720074\n",
      "\n",
      "Generator loss : 1.4032633304595947\n",
      "Child error : 0.03674820810556412\n",
      "\n",
      "Discriminator loss real : 0.6524317264556885\n",
      "Generator loss : 1.4433674812316895\n",
      "Child error : 0.01124237384647131\n",
      "\n",
      "Generator loss : 1.4785343408584595\n",
      "Child error : 0.020471028983592987\n",
      "\n",
      "Discriminator loss real : 0.6774269938468933\n",
      "Generator loss : 1.4987465143203735\n",
      "Child error : 0.02619555965065956\n",
      "\n",
      "Generator loss : 1.488491415977478\n",
      "Child error : 0.024069568142294884\n",
      "\n",
      "Discriminator loss real : 0.6545445919036865\n",
      "Generator loss : 1.4738662242889404\n",
      "Child error : 0.021513981744647026\n",
      "\n",
      "Generator loss : 1.413766622543335\n",
      "Child error : 0.013852189294993877\n",
      "\n",
      "Discriminator loss real : 0.6018332839012146\n",
      "Generator loss : 1.3731982707977295\n",
      "Child error : 0.015533976256847382\n",
      "\n",
      "Generator loss : 1.3267375230789185\n",
      "Child error : 0.020597701892256737\n",
      "\n",
      "Discriminator loss real : 0.5369938015937805\n",
      "Generator loss : 1.2689357995986938\n",
      "Child error : 0.015009048394858837\n",
      "\n",
      "Generator loss : 1.2241382598876953\n",
      "Child error : 0.021353449672460556\n",
      "\n",
      "Discriminator loss real : 0.4736284911632538\n",
      "Generator loss : 1.1651545763015747\n",
      "Child error : 0.011203336529433727\n",
      "\n",
      "Generator loss : 1.1212810277938843\n",
      "Child error : 0.02143069915473461\n",
      "\n",
      "Discriminator loss real : 0.41889703273773193\n",
      "Generator loss : 1.0946707725524902\n",
      "Child error : 0.032244592905044556\n",
      "\n",
      "Generator loss : 1.0401979684829712\n",
      "Child error : 0.01733395643532276\n",
      "\n",
      "Discriminator loss real : 0.37542587518692017\n",
      "Generator loss : 1.0054054260253906\n",
      "Child error : 0.017548514530062675\n",
      "\n",
      "Generator loss : 0.972291111946106\n",
      "Child error : 0.024749839678406715\n",
      "\n",
      "Discriminator loss real : 0.3427196741104126\n",
      "Discriminator loss generated : 1.0744695663452148\n",
      "Generator loss : 0.9413071274757385\n",
      "Child error : 0.02193806879222393\n",
      "\n",
      "Discriminator loss generated : 1.071230411529541\n",
      "Generator loss : 0.9175108671188354\n",
      "Child error : 0.014452106319367886\n",
      "\n",
      "Discriminator loss real : 0.3440539240837097\n",
      "Discriminator loss generated : 0.9881137609481812\n",
      "Generator loss : 0.9350706934928894\n",
      "Child error : 0.027495695278048515\n",
      "\n",
      "Discriminator loss generated : 0.8776317834854126\n",
      "Generator loss : 0.9385681748390198\n",
      "Child error : 0.017262926325201988\n",
      "\n",
      "Discriminator loss real : 0.3751882314682007\n",
      "Discriminator loss generated : 0.7461769580841064\n",
      "Generator loss : 0.9770559072494507\n",
      "Child error : 0.015817750245332718\n",
      "\n",
      "Discriminator loss generated : 0.6204217672348022\n",
      "Generator loss : 1.0467712879180908\n",
      "Child error : 0.02284206636250019\n",
      "\n",
      "Discriminator loss real : 0.4343445599079132\n",
      "Generator loss : 1.1205447912216187\n",
      "Child error : 0.019149819388985634\n",
      "\n",
      "Generator loss : 1.1954454183578491\n",
      "Child error : 0.02249179780483246\n",
      "\n",
      "Discriminator loss real : 0.49202990531921387\n",
      "Generator loss : 1.258678674697876\n",
      "Child error : 0.01863304153084755\n",
      "\n",
      "Generator loss : 1.3091824054718018\n",
      "Child error : 0.024120310321450233\n",
      "\n",
      "Discriminator loss real : 0.5304145216941833\n",
      "Generator loss : 1.346046805381775\n",
      "Child error : 0.019889656454324722\n",
      "\n",
      "Generator loss : 1.3723924160003662\n",
      "Child error : 0.02138199284672737\n",
      "\n",
      "Discriminator loss real : 0.5459186434745789\n",
      "Generator loss : 1.4070062637329102\n",
      "Child error : 0.03627091646194458\n",
      "\n",
      "Generator loss : 1.401313066482544\n",
      "Child error : 0.02748722769320011\n",
      "\n",
      "Discriminator loss real : 0.5404327511787415\n",
      "Generator loss : 1.4053033590316772\n",
      "Child error : 0.02674643136560917\n",
      "\n",
      "Generator loss : 1.3874332904815674\n",
      "Child error : 0.022429494187235832\n",
      "\n",
      "train\n",
      "Generation 2  fitness : 91.0\n",
      "#################################\n",
      "[10. 10.  8.  8.  9.  9.  9.  9.  8.  9.  9. 10.  8.  9. 11. 10. 10.  9.\n",
      " 10.  9. 10. 10. 17. 14. 10. 10. 10. 10.  9.  9. 11.  9. 10.  9. 10. 10.\n",
      " 10.  9. 10. 14.  8.  9.  9. 10.  9.  9. 11. 10. 10.  9.]\n",
      "31.28\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Discriminator loss real : 0.6007629632949829\n",
      "Discriminator loss generated : 0.32163017988204956\n",
      "Generator loss : 1.3709990978240967\n",
      "Child error : 0.006609270814806223\n",
      "\n",
      "Generator loss : 1.3566844463348389\n",
      "Child error : 0.007337274495512247\n",
      "\n",
      "Discriminator loss real : 0.5561960935592651\n",
      "Generator loss : 1.343856930732727\n",
      "Child error : 0.014163391664624214\n",
      "\n",
      "Generator loss : 1.329984188079834\n",
      "Child error : 0.022393399849534035\n",
      "\n",
      "Discriminator loss real : 0.482809841632843\n",
      "Generator loss : 1.2962045669555664\n",
      "Child error : 0.008738012053072453\n",
      "\n",
      "Generator loss : 1.3038239479064941\n",
      "Child error : 0.023002129048109055\n",
      "\n",
      "Discriminator loss real : 0.3970750868320465\n",
      "Generator loss : 1.294306755065918\n",
      "Child error : 0.012998121790587902\n",
      "\n",
      "Generator loss : 1.3116708993911743\n",
      "Child error : 0.017950311303138733\n",
      "\n",
      "Discriminator loss real : 0.31239649653434753\n",
      "Generator loss : 1.3190768957138062\n",
      "Child error : 0.009991642087697983\n",
      "\n",
      "Generator loss : 1.3397331237792969\n",
      "Child error : 0.007356286980211735\n",
      "\n",
      "Discriminator loss real : 0.2372218668460846\n",
      "Generator loss : 1.3615134954452515\n",
      "Child error : 0.009693853557109833\n",
      "\n",
      "Generator loss : 1.3940238952636719\n",
      "Child error : 0.009689800441265106\n",
      "\n",
      "Discriminator loss real : 0.17570610344409943\n",
      "Generator loss : 1.4217910766601562\n",
      "Child error : 0.014425979927182198\n",
      "\n",
      "Generator loss : 1.4483989477157593\n",
      "Child error : 0.01602255366742611\n",
      "\n",
      "Discriminator loss real : 0.12902194261550903\n",
      "Generator loss : 1.4787753820419312\n",
      "Child error : 0.021377576515078545\n",
      "\n",
      "Generator loss : 1.4928643703460693\n",
      "Child error : 0.010852686129510403\n",
      "\n",
      "Discriminator loss real : 0.09532690048217773\n",
      "Generator loss : 1.5223640203475952\n",
      "Child error : 0.019147560000419617\n",
      "\n",
      "Generator loss : 1.5454435348510742\n",
      "Child error : 0.01578499935567379\n",
      "\n",
      "Discriminator loss real : 0.07113433629274368\n",
      "Generator loss : 1.5688141584396362\n",
      "Child error : 0.020641256123781204\n",
      "\n",
      "Generator loss : 1.589612603187561\n",
      "Child error : 0.01957949623465538\n",
      "\n",
      "Discriminator loss real : 0.05430975556373596\n",
      "Generator loss : 1.6060184240341187\n",
      "Child error : 0.01607014425098896\n",
      "\n",
      "Generator loss : 1.6198588609695435\n",
      "Child error : 0.014855918474495411\n",
      "\n",
      "Discriminator loss real : 0.042717095464468\n",
      "Generator loss : 1.6346137523651123\n",
      "Child error : 0.015030959621071815\n",
      "\n",
      "Generator loss : 1.6479535102844238\n",
      "Child error : 0.016651783138513565\n",
      "\n",
      "Discriminator loss real : 0.034556757658720016\n",
      "Generator loss : 1.6664612293243408\n",
      "Child error : 0.022878391668200493\n",
      "\n",
      "Generator loss : 1.678558349609375\n",
      "Child error : 0.021297313272953033\n",
      "\n",
      "Discriminator loss real : 0.028654132038354874\n",
      "Generator loss : 1.6912784576416016\n",
      "Child error : 0.023151149973273277\n",
      "\n",
      "Generator loss : 1.6968311071395874\n",
      "Child error : 0.017158998176455498\n",
      "\n",
      "Discriminator loss real : 0.02425048127770424\n",
      "Generator loss : 1.7109993696212769\n",
      "Child error : 0.019438117742538452\n",
      "\n",
      "Generator loss : 1.7250070571899414\n",
      "Child error : 0.021524030715227127\n",
      "\n",
      "Discriminator loss real : 0.02086634188890457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator loss : 1.7540289163589478\n",
      "Child error : 0.04083265736699104\n",
      "\n",
      "Generator loss : 1.7574349641799927\n",
      "Child error : 0.03306861221790314\n",
      "\n",
      "Discriminator loss real : 0.01821027509868145\n",
      "Generator loss : 1.756635069847107\n",
      "Child error : 0.025309119373559952\n",
      "\n",
      "Generator loss : 1.7782220840454102\n",
      "Child error : 0.0352792888879776\n",
      "\n",
      "Discriminator loss real : 0.016087763011455536\n",
      "Generator loss : 1.7795212268829346\n",
      "Child error : 0.030101412907242775\n",
      "\n",
      "Generator loss : 1.7944554090499878\n",
      "Child error : 0.034418899565935135\n",
      "\n",
      "Discriminator loss real : 0.014367691241204739\n",
      "Generator loss : 1.792473316192627\n",
      "Child error : 0.023051133379340172\n",
      "\n",
      "Generator loss : 1.8023393154144287\n",
      "Child error : 0.02571275271475315\n",
      "\n",
      "Discriminator loss real : 0.012957321479916573\n",
      "Generator loss : 1.8066214323043823\n",
      "Child error : 0.025125592947006226\n",
      "\n",
      "Generator loss : 1.8176604509353638\n",
      "Child error : 0.027811113744974136\n",
      "\n",
      "Discriminator loss real : 0.011788593605160713\n",
      "Generator loss : 1.822015643119812\n",
      "Child error : 0.026476142928004265\n",
      "\n",
      "Generator loss : 1.8398127555847168\n",
      "Child error : 0.03790963813662529\n",
      "\n",
      "Discriminator loss real : 0.010810146108269691\n",
      "Generator loss : 1.829854965209961\n",
      "Child error : 0.024259520694613457\n",
      "\n",
      "Generator loss : 1.8451836109161377\n",
      "Child error : 0.030686309561133385\n",
      "\n",
      "Discriminator loss real : 0.00998353585600853\n",
      "Generator loss : 1.854251503944397\n",
      "Child error : 0.03979578614234924\n",
      "\n",
      "Generator loss : 1.8564941883087158\n",
      "Child error : 0.03515716269612312\n",
      "\n",
      "Discriminator loss real : 0.009279233403503895\n",
      "Generator loss : 1.8634350299835205\n",
      "Child error : 0.03831437975168228\n",
      "\n",
      "Generator loss : 1.8673758506774902\n",
      "Child error : 0.0393160916864872\n",
      "\n",
      "Discriminator loss real : 0.008674170821905136\n",
      "Generator loss : 1.8652899265289307\n",
      "Child error : 0.034844860434532166\n",
      "\n",
      "Generator loss : 1.8825112581253052\n",
      "Child error : 0.046424999833106995\n",
      "\n",
      "train\n",
      "Generation 3  fitness : 17.0\n",
      "#################################\n",
      "[ 84.  79.  44.  18.  71.  48.  20. 143.  27.  37.  65. 133. 238.  14.\n",
      "  96.  20.  84. 107.  94.   9.  27.  46.  78.  27.  81.  17.  12.  66.\n",
      "  25.  10.  65.  67.   9.  46.  19. 107.  24.  15.  27.  60.  14.  18.\n",
      "  22.  48.  93.  72.  17. 111.  11.   9.]\n",
      "53.86\n",
      "[0.35294118 0.33193277 0.         0.         0.29831933 0.\n",
      " 0.         0.60084034 0.         0.         0.27310924 0.55882353\n",
      " 1.         0.         0.40336134 0.         0.35294118 0.44957983\n",
      " 0.39495798 0.         0.         0.         0.32773109 0.\n",
      " 0.34033613 0.         0.         0.27731092 0.         0.\n",
      " 0.27310924 0.28151261 0.         0.         0.         0.44957983\n",
      " 0.         0.         0.         0.25210084 0.         0.\n",
      " 0.         0.         0.3907563  0.30252101 0.         0.46638655\n",
      " 0.         0.        ]\n",
      "Discriminator loss real : 0.3336290717124939\n",
      "Discriminator loss generated : 1.988453984260559\n",
      "Generator loss : 2.004404306411743\n",
      "Child error : 0.016896085813641548\n",
      "\n",
      "Generator loss : 1.917816162109375\n",
      "Child error : 0.01209146436303854\n",
      "\n",
      "Discriminator loss real : 0.32865989208221436\n",
      "Generator loss : 1.8571795225143433\n",
      "Child error : 0.007646435406059027\n",
      "\n",
      "Generator loss : 1.787510871887207\n",
      "Child error : 0.0076022217981517315\n",
      "\n",
      "Discriminator loss real : 0.3209545612335205\n",
      "Generator loss : 1.7404996156692505\n",
      "Child error : 0.014628631062805653\n",
      "\n",
      "Generator loss : 1.6741909980773926\n",
      "Child error : 0.011469468474388123\n",
      "\n",
      "Discriminator loss real : 0.31148356199264526\n",
      "Generator loss : 1.6160858869552612\n",
      "Child error : 0.005781281739473343\n",
      "\n",
      "Generator loss : 1.5631592273712158\n",
      "Child error : 0.013325529173016548\n",
      "\n",
      "Discriminator loss real : 0.30136775970458984\n",
      "Generator loss : 1.504046082496643\n",
      "Child error : 0.006519000511616468\n",
      "\n",
      "Generator loss : 1.4522700309753418\n",
      "Child error : 0.013401607051491737\n",
      "\n",
      "Discriminator loss real : 0.2915399670600891\n",
      "Generator loss : 1.3937406539916992\n",
      "Child error : 0.008205359801650047\n",
      "\n",
      "Generator loss : 1.3349339962005615\n",
      "Child error : 0.00880714412778616\n",
      "\n",
      "Discriminator loss real : 0.2827650010585785\n",
      "Generator loss : 1.285226821899414\n",
      "Child error : 0.013020984828472137\n",
      "\n",
      "Generator loss : 1.220276951789856\n",
      "Child error : 0.00652663130313158\n",
      "\n",
      "Discriminator loss real : 0.27558812499046326\n",
      "Generator loss : 1.181057333946228\n",
      "Child error : 0.01859370432794094\n",
      "\n",
      "Generator loss : 1.1298385858535767\n",
      "Child error : 0.021364320069551468\n",
      "\n",
      "Discriminator loss real : 0.27022209763526917\n",
      "Generator loss : 1.0662763118743896\n",
      "Child error : 0.005416630767285824\n",
      "\n",
      "Generator loss : 1.030104160308838\n",
      "Child error : 0.016590936109423637\n",
      "\n",
      "Discriminator loss real : 0.26660826802253723\n",
      "Generator loss : 0.9787662029266357\n",
      "Child error : 0.006227120291441679\n",
      "\n",
      "Discriminator loss generated : 1.3862589597702026\n",
      "Generator loss : 0.9532686471939087\n",
      "Child error : 0.021095946431159973\n",
      "\n",
      "Discriminator loss real : 0.26862579584121704\n",
      "Discriminator loss generated : 1.3383773565292358\n",
      "Generator loss : 0.9259744882583618\n",
      "Child error : 0.013781233690679073\n",
      "\n",
      "Discriminator loss generated : 1.2468819618225098\n",
      "Generator loss : 0.9134956002235413\n",
      "Child error : 0.006045143119990826\n",
      "\n",
      "Discriminator loss real : 0.28760188817977905\n",
      "Discriminator loss generated : 1.1203609704971313\n",
      "Generator loss : 0.9422421455383301\n",
      "Child error : 0.020871305838227272\n",
      "\n",
      "Discriminator loss generated : 0.9837762713432312\n",
      "Generator loss : 0.9679738283157349\n",
      "Child error : 0.013591851107776165\n",
      "\n",
      "Discriminator loss real : 0.32777613401412964\n",
      "Discriminator loss generated : 0.845394492149353\n",
      "Generator loss : 1.0285682678222656\n",
      "Child error : 0.01742258481681347\n",
      "\n",
      "Generator loss : 1.1016368865966797\n",
      "Child error : 0.01899983361363411\n",
      "\n",
      "Discriminator loss real : 0.3912067115306854\n",
      "Generator loss : 1.1612247228622437\n",
      "Child error : 0.011566138826310635\n",
      "\n",
      "Generator loss : 1.2210956811904907\n",
      "Child error : 0.014072000049054623\n",
      "\n",
      "Discriminator loss real : 0.45307618379592896\n",
      "Generator loss : 1.261271357536316\n",
      "Child error : 0.00664552254602313\n",
      "\n",
      "Generator loss : 1.2993500232696533\n",
      "Child error : 0.00713971396908164\n",
      "\n",
      "Discriminator loss real : 0.5007039308547974\n",
      "Generator loss : 1.3306618928909302\n",
      "Child error : 0.007867710664868355\n",
      "\n",
      "Generator loss : 1.347123146057129\n",
      "Child error : 0.005331250373274088\n",
      "\n",
      "Discriminator loss real : 0.5276339054107666\n",
      "Generator loss : 1.370010495185852\n",
      "Child error : 0.012947156094014645\n",
      "\n",
      "Generator loss : 1.368817687034607\n",
      "Child error : 0.008638903498649597\n",
      "\n",
      "Discriminator loss real : 0.5336143374443054\n",
      "Generator loss : 1.3744783401489258\n",
      "Child error : 0.014048650860786438\n",
      "\n",
      "Generator loss : 1.3592404127120972\n",
      "Child error : 0.006606286857277155\n",
      "\n",
      "Discriminator loss real : 0.5225858092308044\n"
     ]
    }
   ],
   "source": [
    "#randomly inititialise starting population\n",
    "population_size = 50\n",
    "population = []\n",
    "for p in range(population_size):\n",
    "    population.append(Creature().to(device))\n",
    "    \n",
    "gen = Generator(86).to(device)\n",
    "#gen(torch.zeros([10,86*2])).shape\n",
    "\n",
    "dis = Discriminator().to(device)\n",
    "#dis(torch.zeros([10,86])).shape\n",
    "\n",
    "lr = 0.0002\n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "\n",
    "print(\"starting training\")\n",
    "n_generations = 100\n",
    "batch_size = 50\n",
    "for i in range(n_generations):\n",
    "    #gen = Generator(86).to(device)\n",
    "    #dis = Discriminator().to(device)\n",
    "    gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "    #dis_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_behavior_samples = 50\n",
    "    p_fitness, behavior_samples = measure_population_fitness(population,env,device,discrete_actions,\n",
    "                                                             max_steps = 500, \n",
    "                                                             n_behavior_samples=n_behavior_samples)\n",
    "    print(p_fitness)\n",
    "    if i == 0:\n",
    "        old_fitness = p_fitness\n",
    "    \n",
    "    if i == 0:\n",
    "        train_gan(population,p_fitness,old_fitness,batch_size = batch_size,n_epochs = 150)\n",
    "        #dis_optimizer = torch.optim.Adam(dis.parameters(), lr=0.00001)\n",
    "        print(\"train\")\n",
    "    else:\n",
    "        train_gan(population,p_fitness,old_fitness,batch_size = batch_size,n_epochs = 50)\n",
    "        print(\"train\")\n",
    "    old_fitness = p_fitness\n",
    "    \n",
    "    \n",
    "   # if i % 1 == 0:\n",
    "      #  fitness = measure_fitness(population[np.argmax(p_fitness)],env,device,discrete_actions,render = True)\n",
    "    population = evolve(population,gen,p_fitness,True)\n",
    "    print(\"Generation {}  fitness : {}\".format(i+1,np.max(p_fitness)))\n",
    "    print(\"#################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeet  = np.arange(10) + 5\n",
    "print(yeet)\n",
    "yeet = np.delete(yeet,np.where(yeet<7)[0])\n",
    "print(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
